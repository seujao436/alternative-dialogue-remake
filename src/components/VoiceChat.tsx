import React, { useState, useEffect, useRef } from 'react'
import { Mic, MicOff, Volume2, VolumeX } from 'lucide-react'

interface VoiceChatProps {
  apiKey: string
  selectedVoice: string
  isConnected: boolean
  isRecording: boolean
  isPlaying: boolean
  onConnectionChange: (connected: boolean) => void
  onRecordingChange: (recording: boolean) => void
  onPlayingChange: (playing: boolean) => void
  onMessage: (type: 'user' | 'assistant', content: string, isAudio?: boolean) => void
}

interface Voice {
  id: string
  name: string
  description: string
}

const VoiceChat: React.FC<VoiceChatProps> = ({
  apiKey,
  selectedVoice,
  isConnected,
  isRecording,
  isPlaying,
  onConnectionChange,
  onRecordingChange,
  onPlayingChange,
  onMessage
}) => {
  const [websocket, setWebsocket] = useState<WebSocket | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const audioContextRef = useRef<AudioContext | null>(null)

  // Lista de vozes dispon√≠veis
  const voices: Voice[] = [
    { id: 'Puck', name: 'Puck - Masculino Jovem', description: 'Voz energ√©tica' },
    { id: 'Charon', name: 'Charon - Masculino Maduro', description: 'Voz s√°bia' },
    { id: 'Kore', name: 'Kore - Feminino Jovem', description: 'Voz clara' },
    { id: 'Fenrir', name: 'Fenrir - Masculino Grave', description: 'Voz profunda' },
    { id: 'Aoede', name: 'Aoede - Feminino Melodioso', description: 'Voz musical' }
  ]

  // Conectar √† API Gemini Live
  const connectToGemini = async () => {
    if (!apiKey) {
      onMessage('assistant', '‚ùå Configure sua chave da API primeiro!')
      return
    }

    try {
      // Simular conex√£o WebSocket com a API Gemini Live
      // Nota: Esta √© uma implementa√ß√£o simplificada
      // A implementa√ß√£o real requer integra√ß√£o com @google/genai
      onMessage('assistant', 'üü¢ Simulando conex√£o com Gemini Live...')
      onConnectionChange(true)
      
      // Simular resposta de conex√£o
      setTimeout(() => {
        onMessage('assistant', '‚úÖ Conectado! Pode come√ßar a falar.')
      }, 1000)
      
    } catch (error) {
      console.error('Erro ao conectar:', error)
      onMessage('assistant', 'Erro de conex√£o. Verifique sua API key.')
      onConnectionChange(false)
    }
  }

  // Iniciar grava√ß√£o de √°udio
  const startRecording = async () => {
    if (!isConnected) {
      await connectToGemini()
      return
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })

      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })

      audioChunksRef.current = []

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorderRef.current.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        await processAudio(audioBlob)
        
        // Parar todas as faixas de √°udio
        stream.getTracks().forEach(track => track.stop())
      }

      mediaRecorderRef.current.start(1000) // Capturar dados a cada 1 segundo
      onRecordingChange(true)
      onMessage('user', 'üé§ Gravando...', true)

    } catch (error) {
      console.error('Erro ao acessar microfone:', error)
      onMessage('assistant', '‚ùå Erro ao acessar microfone. Permita o acesso!')
    }
  }

  // Parar grava√ß√£o
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      onRecordingChange(false)
    }
  }

  // Processar √°udio gravado
  const processAudio = async (audioBlob: Blob) => {
    try {
      onMessage('user', '‚úÖ √Åudio capturado', true)
      
      // Simular processamento e resposta da IA
      setTimeout(() => {
        const responses = [
          'Ol√°! Como posso ajudar voc√™ hoje?',
          'Que interessante! Pode me contar mais sobre isso?',
          'Entendo sua pergunta. Vou pensar na melhor resposta.',
          'Essa √© uma √≥tima quest√£o! Deixe-me explicar...',
          'Posso ajudar com isso. Qual seria sua prefer√™ncia?'
        ]
        
        const randomResponse = responses[Math.floor(Math.random() * responses.length)]
        onMessage('assistant', randomResponse, true)
        
        // Simular reprodu√ß√£o de √°udio
        playAudioResponse(randomResponse)
      }, 1500)
      
    } catch (error) {
      console.error('Erro ao processar √°udio:', error)
      onMessage('assistant', '‚ùå Erro ao processar √°udio')
    }
  }

  // Simular reprodu√ß√£o de resposta em √°udio
  const playAudioResponse = async (text: string) => {
    try {
      onPlayingChange(true)
      
      // Simular tempo de reprodu√ß√£o baseado no tamanho do texto
      const playTime = Math.max(2000, text.length * 50)
      
      setTimeout(() => {
        onPlayingChange(false)
      }, playTime)
      
    } catch (error) {
      console.error('Erro ao reproduzir √°udio:', error)
      onPlayingChange(false)
    }
  }

  // Toggle grava√ß√£o
  const toggleRecording = () => {
    if (isRecording) {
      stopRecording()
    } else {
      startRecording()
    }
  }

  // Status da aplica√ß√£o
  const getStatusText = () => {
    if (!apiKey) return 'Configure a API Key'
    if (!isConnected) return 'Clique para conectar'
    if (isRecording) return 'Gravando... Clique para parar'
    if (isPlaying) return 'Reproduzindo resposta...'
    return 'Clique para falar'
  }

  const getStatusClass = () => {
    if (isRecording) return 'recording'
    if (isPlaying) return 'playing'
    return 'idle'
  }

  return (
    <div className="voice-chat">
      <button
        className={`mic-button ${isRecording ? 'recording' : ''}`}
        onClick={toggleRecording}
        disabled={!apiKey || isPlaying}
      >
        {isRecording ? <MicOff size={40} /> : <Mic size={40} />}
      </button>

      <div className={`voice-status ${getStatusClass()}`}>
        <p>{getStatusText()}</p>
      </div>

      {isConnected && (
        <div className="voice-info">
          <p>üéµ Voz: <strong>{voices.find(v => v.id === selectedVoice)?.name || selectedVoice}</strong></p>
          <p>{isPlaying ? <Volume2 size={16} /> : <VolumeX size={16} />} {isPlaying ? 'Reproduzindo' : 'Sil√™ncio'}</p>
        </div>
      )}

      {!apiKey && (
        <div className="api-warning">
          <p>‚ö†Ô∏è Configure sua chave da API Gemini</p>
        </div>
      )}
    </div>
  )
}

export default VoiceChat